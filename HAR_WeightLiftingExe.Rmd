---
title: "Course Project for Machine Learning"
author: "Canqing YU"
date: "Sunday, July 27, 2014"
output: html_document
---

This is the course project for *Practical Machine Learning* in data science specialization. The *Weight Lifting Exercise Dataset* for this project come from this source: [http://groupware.les.inf.puc-rio.br/har](http://groupware.les.inf.puc-rio.br/har).

#### Read in data

First of all, read in the training and testing dataset.

```{r read, cache=TRUE}
setwd("K:/MOOCs - Data Science Specialization/8. Practical Machine Learning/Writeup")
if (!file.exists("pml-training.csv")){download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile="pml-training.csv", method="curl")}
if (!file.exists("pml-testing.csv")){download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile="pml-testing.csv", method="curl")}
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
```

#### Data exploration

Preliminary data cleaning and exploration:

- delete the `NA` variables
- delete the variables which have a large proportion of empty values
- delete irrelevant variables

```{r explore, cache=TRUE}
dim(training)
dim(testing)
clean1 <- training[,!apply(training,2,anyNA)] #delete NA columns
clean2 <- clean1[,apply(clean1,2,function(x){sum(x=='')==0})] #delete empty columns 
clean3 <- clean2[,-(1:7)] #remove irrelarent variables
colnames(clean3)
```

#### Split data

Split the `training` data set into `train` and `test` data sets, with the proportions of 60% and 40%. So we could estimate the out-of-sample error.

```{r splitdata, cache=TRUE}
suppressPackageStartupMessages(library(caret))
set.seed(20140727)
inTrain <- createDataPartition(y=clean3$classe, p=0.6, list=FALSE)
train <- clean3[inTrain,]
test <- clean3[-inTrain,]
```

#### Model fitting

In order to boost the process of computing, `doParallel` package was used to create a cluster for multiple cores. As for the model fitting, `caret` package was used to apply the `random forest` method to train the machine learning algorithm. 

```{r randomForest}
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(doParallel))
cl<-makeCluster(6)
registerDoParallel(cl)
fitControl <- trainControl(method='cv', number=3)
modFit <- train(classe~., method='rf', trControl=fitControl, data=train)
stopCluster(cl)
```

#### Cross validation

As we could see in the results, a perfect accuracy in the `train` data set, and 99.2% in the `test` data set.

```{r pred}
pred_train <- predict(modFit, newdata=train[,-53])
confusionMatrix(pred_train, train$classe)
pred_test <- predict(modFit, newdata=test[,-53])
confusionMatrix(pred_test, test$classe)
plot(varImp(modFit), main="Variable importance of 52 in prediction model")
```

From the variable importance plot, we could see the `roll_belt` is most important variable.

#### Prediction with test data set

Apply the algorithm generated from `training` data set by the machine learning model, we could predict the 20 samples in the `testing` data set.

```{r predtest, cache=TRUE}
answers <- as.character(predict(modFit, testing))
answers
```

